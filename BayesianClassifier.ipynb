{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBA / DMG2 / Supervised Learning Homework Assignment - 1\n",
    "\n",
    "\n",
    "Submitted By: <b>Amit Kumar Sharma (PGID: 71721079)<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 – MNSIT Bayesian\n",
    "\n",
    "    •\tTake the MNIST dataset. Lets call it D0 dataset\n",
    "    •\tDo a 9 dimensional PCA projection. Lets call it D1 dataset\n",
    "    •\tDo a 9 dimensional FISHER projection. Lets call it D2 dataset\n",
    "    •\tBuild a Bayesian classifier on D1 (single Gaussian per class)\n",
    "        •\tDiagonal Covariance matrix (i.e.set non-diagonals to zero) \n",
    "        •\tFull Covariance matrix\n",
    "    •\tBuild a Bayesian classifier on D2 (single Gaussian per class)\n",
    "        •\tDiagonal Covariance\n",
    "        •\tFull covariance\n",
    "    •\tCompare the test accuracies of the four classifiers and comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Take the MNIST dataset. Lets call it D0 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "for i in range(0,10):\n",
    "    file = '/Users/a5sharma/Documents/ISB/DMG2/Assignment/data/MNIST/train'+str(i)+'.csv'\n",
    "    temp = pd.read_csv(file,low_memory=False)\n",
    "    temp = temp.iloc[:,1:]\n",
    "    temp['label'] = i\n",
    "    if i == 0:\n",
    "        train = temp\n",
    "    else:\n",
    "        train = pd.concat([train, temp],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "for i in range(0,10):\n",
    "    file = '/Users/a5sharma/Documents/ISB/DMG2/Assignment/data/MNIST/test'+str(i)+'.csv'\n",
    "    temp = pd.read_csv(file,low_memory=False)\n",
    "    temp = temp.iloc[:,1:]\n",
    "    temp['label'] = i\n",
    "    if i == 0:\n",
    "        test = temp\n",
    "    else:\n",
    "        test = pd.concat([test, temp],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Missing Values\n",
    "There are lots of missing values in training and testing dataset and all variables are empty for all missing rows. We need to remove all the missing rows further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       391\n",
       "V2       391\n",
       "V3       391\n",
       "V4       391\n",
       "V5       391\n",
       "V6       391\n",
       "V7       391\n",
       "V8       391\n",
       "V9       391\n",
       "V10      391\n",
       "V11      391\n",
       "V12      391\n",
       "V13      391\n",
       "V14      391\n",
       "V15      391\n",
       "V16      391\n",
       "V17      391\n",
       "V18      391\n",
       "V19      391\n",
       "V20      391\n",
       "V21      391\n",
       "V22      391\n",
       "V23      391\n",
       "V24      391\n",
       "V25      391\n",
       "V26      391\n",
       "V27      391\n",
       "V28      391\n",
       "V29      391\n",
       "V30      391\n",
       "        ... \n",
       "V756     391\n",
       "V757     391\n",
       "V758     391\n",
       "V759     391\n",
       "V760     391\n",
       "V761     391\n",
       "V762     391\n",
       "V763     391\n",
       "V764     391\n",
       "V765     391\n",
       "V766     391\n",
       "V767     391\n",
       "V768     391\n",
       "V769     391\n",
       "V770     391\n",
       "V771     391\n",
       "V772     391\n",
       "V773     391\n",
       "V774     391\n",
       "V775     391\n",
       "V776     391\n",
       "V777     391\n",
       "V778     391\n",
       "V779     391\n",
       "V780     391\n",
       "V781     391\n",
       "V782     391\n",
       "V783     391\n",
       "V784     391\n",
       "label      0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.dropna(axis=0,inplace=True)\n",
    "test.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35750 entries, 0 to 36140\n",
      "Columns: 785 entries, V1 to label\n",
      "dtypes: float64(784), int64(1)\n",
      "memory usage: 214.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24250 entries, 0 to 24518\n",
      "Columns: 785 entries, V1 to label\n",
      "dtypes: float64(784), int64(1)\n",
      "memory usage: 145.4 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V775</th>\n",
       "      <th>V776</th>\n",
       "      <th>V777</th>\n",
       "      <th>V778</th>\n",
       "      <th>V779</th>\n",
       "      <th>V780</th>\n",
       "      <th>V781</th>\n",
       "      <th>V782</th>\n",
       "      <th>V783</th>\n",
       "      <th>V784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...   V775  V776  V777  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "\n",
       "   V778  V779  V780  V781  V782  V783  V784  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:,0:784].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Normalization\n",
    "\n",
    "Lets Normalize both the datasets before applying LDA or PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,0:784]/255.0\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "X_test = test.iloc[:,0:784]/255.0\n",
    "y_test = test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do a 9 dimensional PCA projection. Lets call it D1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.10335982 3.74717042 3.23910925 2.83450361 2.57223319 2.26820366\n",
      " 1.72876292 1.51358699 1.44555369]\n",
      "Explained variation per principal component: [0.09694147 0.07117981 0.06152888 0.05384314 0.04886116 0.04308593\n",
      " 0.03283892 0.02875152 0.02745918]\n",
      "Explained cumulative variation for 2 principal components: [0.09694147 0.16812128 0.22965016 0.2834933  0.33235446 0.37544039\n",
      " 0.4082793  0.43703082 0.46449001]\n",
      "The dimensions of PCA projection Data Frame: (35750, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.028728</td>\n",
       "      <td>-1.062822</td>\n",
       "      <td>2.442987</td>\n",
       "      <td>-1.830775</td>\n",
       "      <td>-3.152218</td>\n",
       "      <td>-0.620715</td>\n",
       "      <td>-0.152372</td>\n",
       "      <td>-0.399007</td>\n",
       "      <td>0.213673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.122160</td>\n",
       "      <td>-1.303177</td>\n",
       "      <td>2.160442</td>\n",
       "      <td>-2.171781</td>\n",
       "      <td>-3.408331</td>\n",
       "      <td>0.089392</td>\n",
       "      <td>-0.173005</td>\n",
       "      <td>0.207913</td>\n",
       "      <td>1.964713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.412930</td>\n",
       "      <td>-0.853290</td>\n",
       "      <td>2.724968</td>\n",
       "      <td>-2.498519</td>\n",
       "      <td>1.573210</td>\n",
       "      <td>-1.656461</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>1.988436</td>\n",
       "      <td>0.456747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.532352</td>\n",
       "      <td>-0.329908</td>\n",
       "      <td>-0.559258</td>\n",
       "      <td>-3.094260</td>\n",
       "      <td>-2.990228</td>\n",
       "      <td>1.832665</td>\n",
       "      <td>-0.603947</td>\n",
       "      <td>-1.599748</td>\n",
       "      <td>1.226512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.162878</td>\n",
       "      <td>0.045781</td>\n",
       "      <td>-1.127272</td>\n",
       "      <td>-1.032655</td>\n",
       "      <td>-2.616755</td>\n",
       "      <td>2.245742</td>\n",
       "      <td>1.285621</td>\n",
       "      <td>-2.519399</td>\n",
       "      <td>1.953335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.828110</td>\n",
       "      <td>-0.635625</td>\n",
       "      <td>-0.698679</td>\n",
       "      <td>-2.246634</td>\n",
       "      <td>1.644010</td>\n",
       "      <td>-1.638070</td>\n",
       "      <td>0.584425</td>\n",
       "      <td>0.952081</td>\n",
       "      <td>0.928532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.342471</td>\n",
       "      <td>-1.600990</td>\n",
       "      <td>0.796915</td>\n",
       "      <td>-3.047240</td>\n",
       "      <td>-0.912178</td>\n",
       "      <td>-0.780914</td>\n",
       "      <td>-0.960354</td>\n",
       "      <td>1.927253</td>\n",
       "      <td>1.115426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.219502</td>\n",
       "      <td>-0.822439</td>\n",
       "      <td>1.583716</td>\n",
       "      <td>-3.512004</td>\n",
       "      <td>-0.030552</td>\n",
       "      <td>-1.995429</td>\n",
       "      <td>-0.691501</td>\n",
       "      <td>1.047912</td>\n",
       "      <td>-0.413527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.595544</td>\n",
       "      <td>-1.395223</td>\n",
       "      <td>-2.461960</td>\n",
       "      <td>0.507267</td>\n",
       "      <td>-2.793008</td>\n",
       "      <td>2.513274</td>\n",
       "      <td>0.632571</td>\n",
       "      <td>-1.514705</td>\n",
       "      <td>0.039801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.399449</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>-0.060062</td>\n",
       "      <td>-1.375413</td>\n",
       "      <td>-4.335054</td>\n",
       "      <td>0.696019</td>\n",
       "      <td>1.522625</td>\n",
       "      <td>-1.521426</td>\n",
       "      <td>2.403929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pca0      pca1      pca2      pca3      pca4      pca5      pca6  \\\n",
       "0  4.028728 -1.062822  2.442987 -1.830775 -3.152218 -0.620715 -0.152372   \n",
       "1  4.122160 -1.303177  2.160442 -2.171781 -3.408331  0.089392 -0.173005   \n",
       "2  2.412930 -0.853290  2.724968 -2.498519  1.573210 -1.656461  0.004307   \n",
       "3  6.532352 -0.329908 -0.559258 -3.094260 -2.990228  1.832665 -0.603947   \n",
       "4  5.162878  0.045781 -1.127272 -1.032655 -2.616755  2.245742  1.285621   \n",
       "5  4.828110 -0.635625 -0.698679 -2.246634  1.644010 -1.638070  0.584425   \n",
       "6  3.342471 -1.600990  0.796915 -3.047240 -0.912178 -0.780914 -0.960354   \n",
       "7  4.219502 -0.822439  1.583716 -3.512004 -0.030552 -1.995429 -0.691501   \n",
       "8  4.595544 -1.395223 -2.461960  0.507267 -2.793008  2.513274  0.632571   \n",
       "9  5.399449  0.019286 -0.060062 -1.375413 -4.335054  0.696019  1.522625   \n",
       "\n",
       "       pca7      pca8  label  \n",
       "0 -0.399007  0.213673      0  \n",
       "1  0.207913  1.964713      0  \n",
       "2  1.988436  0.456747      0  \n",
       "3 -1.599748  1.226512      0  \n",
       "4 -2.519399  1.953335      0  \n",
       "5  0.952081  0.928532      0  \n",
       "6  1.927253  1.115426      0  \n",
       "7  1.047912 -0.413527      0  \n",
       "8 -1.514705  0.039801      0  \n",
       "9 -1.521426  2.403929      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set the seed\n",
    "np.random.seed(1234)\n",
    "\n",
    "## Generate 9 Principle Components\n",
    "pca = PCA(n_components = 9)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_)\n",
    "print('Explained variation per principal component: {0}'.format(pca.explained_variance_ratio_))\n",
    "print('Explained cumulative variation for 2 principal components: {0}'.format(pca.explained_variance_ratio_.cumsum()))\n",
    "\n",
    "col_names = [ 'pca'+str(i) for i in range(0,9) ]\n",
    "digit_pca_9 = pd.DataFrame(pca.transform(X_train), columns = col_names)\n",
    "\n",
    "Y = pd.DataFrame(np.array(y_train), columns=[\"label\"])\n",
    "\n",
    "d1 = pd.concat([digit_pca_9, Y], axis=1)\n",
    "\n",
    "print(\"The dimensions of PCA projection Data Frame: {0}\".format(digit_pca_9.shape))\n",
    "\n",
    "d1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do a 9 dimensional FISHER projection. Lets call it D2 dataset\n",
    "\n",
    "LinearDiscriminantAnalysis is giving \"Variables are collinear.\" warning because there are many variables are linearly related to each other. Also, lots are variables having 0 values for all the observation.\n",
    "\n",
    "I tried to remove all the variables which is having 0 values and run LDA but still got the same warning. Then, I tried to fit a LinearRegression in R and checked VIF for my LinearRegression model in R. After that, I found V13,V15,V393,V644,V727 variables are linearly related. I removing these variables, \"Variables are collinear.\" warning is gone. But we got same projection before removing the variables and after removing the variables. In this workbook, I have not removed these variables as they is no changes before and after.\n",
    "\n",
    "    #R\n",
    "    X = data[,1:ncol(data)-1]\n",
    "    total = dim(X)[1]\n",
    "    colName = colnames(X)\n",
    "    ls = list()\n",
    "    j = 1\n",
    "    for (i in 1:length(colName)){\n",
    "      col = colName[i]\n",
    "      size = dim(X[X[[i]]==0,])[1]\n",
    "      print(col)\n",
    "      if (size == total){\n",
    "        ls[j] = i\n",
    "        j = j + 1\n",
    "      }\n",
    "    }\n",
    "    X1 = X[,-c(array((unlist(ls))),13,15,393)]\n",
    "    X1$label = data$label\n",
    "    model = lm(label ~ ., data = X1)\n",
    "    ld.vars <- attributes(alias(model)$Complete)$dimnames[[1]]\n",
    "    formula.new <- as.formula(\n",
    "      paste(\n",
    "        paste(deparse(label ~ .), collapse=\"\"), \n",
    "        paste(ld.vars, collapse=\"-\"),\n",
    "        sep=\"-\"\n",
    "      )\n",
    "    )\n",
    "    data = data[,-c(as.array(unlist(ls)),13,15,393)]\n",
    "    lda <- lda(label ~ . - V644 - V727 , data = data)\n",
    "\n",
    "    #Python\n",
    "    mismatch = False\n",
    "    for i in range(d2.shape[0]):\n",
    "        x1 = d2.iloc[i,:]\n",
    "        for j in range(x1.shape[0]):\n",
    "            if round(d2.iloc[i,j],5) != round(d3.iloc[i,j],5):\n",
    "                mismatch = True\n",
    "\n",
    "    if(mismatch):\n",
    "        print(\"Not Same\")\n",
    "    else:\n",
    "        print(\"Both are same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a5sharma/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/Users/a5sharma/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lda0</th>\n",
       "      <th>lda1</th>\n",
       "      <th>lda2</th>\n",
       "      <th>lda3</th>\n",
       "      <th>lda4</th>\n",
       "      <th>lda5</th>\n",
       "      <th>lda6</th>\n",
       "      <th>lda7</th>\n",
       "      <th>lda8</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.887029</td>\n",
       "      <td>-3.310528</td>\n",
       "      <td>-2.786562</td>\n",
       "      <td>0.058788</td>\n",
       "      <td>-3.018495</td>\n",
       "      <td>-0.674304</td>\n",
       "      <td>0.506955</td>\n",
       "      <td>-0.842984</td>\n",
       "      <td>-0.173764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.894420</td>\n",
       "      <td>-2.425312</td>\n",
       "      <td>-3.999679</td>\n",
       "      <td>-0.175208</td>\n",
       "      <td>-2.729570</td>\n",
       "      <td>-1.044016</td>\n",
       "      <td>1.235900</td>\n",
       "      <td>0.358109</td>\n",
       "      <td>-0.262772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.860135</td>\n",
       "      <td>-0.965014</td>\n",
       "      <td>-0.857678</td>\n",
       "      <td>-0.730400</td>\n",
       "      <td>-0.502527</td>\n",
       "      <td>0.296998</td>\n",
       "      <td>-1.284739</td>\n",
       "      <td>-1.513364</td>\n",
       "      <td>1.468125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.865351</td>\n",
       "      <td>-2.825316</td>\n",
       "      <td>-4.989777</td>\n",
       "      <td>0.231808</td>\n",
       "      <td>-0.884555</td>\n",
       "      <td>-1.196797</td>\n",
       "      <td>-0.355758</td>\n",
       "      <td>-0.332597</td>\n",
       "      <td>0.916868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.586286</td>\n",
       "      <td>-4.069599</td>\n",
       "      <td>-4.047539</td>\n",
       "      <td>-0.915669</td>\n",
       "      <td>-2.696322</td>\n",
       "      <td>-1.525039</td>\n",
       "      <td>-1.641412</td>\n",
       "      <td>-0.083102</td>\n",
       "      <td>-0.023521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.456195</td>\n",
       "      <td>-2.977401</td>\n",
       "      <td>-2.439679</td>\n",
       "      <td>-0.070588</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.594510</td>\n",
       "      <td>-0.426037</td>\n",
       "      <td>-1.286878</td>\n",
       "      <td>1.460801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.362356</td>\n",
       "      <td>-1.329942</td>\n",
       "      <td>-3.998065</td>\n",
       "      <td>-0.273734</td>\n",
       "      <td>-1.020206</td>\n",
       "      <td>0.205699</td>\n",
       "      <td>1.455731</td>\n",
       "      <td>-1.140298</td>\n",
       "      <td>0.955281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.368090</td>\n",
       "      <td>-2.663745</td>\n",
       "      <td>-2.640072</td>\n",
       "      <td>-0.351479</td>\n",
       "      <td>-0.496984</td>\n",
       "      <td>0.606974</td>\n",
       "      <td>-0.583543</td>\n",
       "      <td>-0.090488</td>\n",
       "      <td>0.335246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.794333</td>\n",
       "      <td>-2.440993</td>\n",
       "      <td>-4.080267</td>\n",
       "      <td>0.533639</td>\n",
       "      <td>-2.163575</td>\n",
       "      <td>-1.261034</td>\n",
       "      <td>0.077082</td>\n",
       "      <td>-1.212496</td>\n",
       "      <td>0.325180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3.801034</td>\n",
       "      <td>-4.642088</td>\n",
       "      <td>-3.061066</td>\n",
       "      <td>-0.319711</td>\n",
       "      <td>-3.782619</td>\n",
       "      <td>-1.189575</td>\n",
       "      <td>0.343004</td>\n",
       "      <td>-1.708295</td>\n",
       "      <td>0.630156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lda0      lda1      lda2      lda3      lda4      lda5      lda6  \\\n",
       "0 -2.887029 -3.310528 -2.786562  0.058788 -3.018495 -0.674304  0.506955   \n",
       "1 -1.894420 -2.425312 -3.999679 -0.175208 -2.729570 -1.044016  1.235900   \n",
       "2 -2.860135 -0.965014 -0.857678 -0.730400 -0.502527  0.296998 -1.284739   \n",
       "3 -2.865351 -2.825316 -4.989777  0.231808 -0.884555 -1.196797 -0.355758   \n",
       "4 -3.586286 -4.069599 -4.047539 -0.915669 -2.696322 -1.525039 -1.641412   \n",
       "5 -3.456195 -2.977401 -2.439679 -0.070588  0.010821  0.594510 -0.426037   \n",
       "6 -2.362356 -1.329942 -3.998065 -0.273734 -1.020206  0.205699  1.455731   \n",
       "7 -3.368090 -2.663745 -2.640072 -0.351479 -0.496984  0.606974 -0.583543   \n",
       "8 -2.794333 -2.440993 -4.080267  0.533639 -2.163575 -1.261034  0.077082   \n",
       "9 -3.801034 -4.642088 -3.061066 -0.319711 -3.782619 -1.189575  0.343004   \n",
       "\n",
       "       lda7      lda8  label  \n",
       "0 -0.842984 -0.173764      0  \n",
       "1  0.358109 -0.262772      0  \n",
       "2 -1.513364  1.468125      0  \n",
       "3 -0.332597  0.916868      0  \n",
       "4 -0.083102 -0.023521      0  \n",
       "5 -1.286878  1.460801      0  \n",
       "6 -1.140298  0.955281      0  \n",
       "7 -0.090488  0.335246      0  \n",
       "8 -1.212496  0.325180      0  \n",
       "9 -1.708295  0.630156      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "d2 = lda.fit_transform(X_train, y_train)\n",
    "col_names = [ 'lda'+str(i) for i in range(0,9) ]\n",
    "digit_lda_9 = pd.DataFrame(d2, columns = col_names)\n",
    "\n",
    "Y = pd.DataFrame(np.array(y_train), columns=[\"label\"])\n",
    "\n",
    "d2 = pd.concat([digit_lda_9, Y], axis=1)\n",
    "d2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build a Bayesian classifier on\tD1 (single Gaussian per class)\n",
    "Diagonal Covariance matrix (i.e.set non-diagonals to zero)<br>\n",
    "Full Covariance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "class BayesianClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, covariance_type='full'):\n",
    "        self.covariance_type = covariance_type\n",
    "        self.gaussians = dict()\n",
    "        self.priors = dict()\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        labels = set(y)\n",
    "        for c in labels:\n",
    "            current_x = X[y==c]\n",
    "            if self.covariance_type == 'full':\n",
    "                cov = current_x.cov()\n",
    "            elif self.covariance_type == 'diag':\n",
    "                cov = current_x.cov()\n",
    "                cov = np.diag(np.diag(cov))\n",
    "            self.gaussians[c] = {\n",
    "                'mean' : current_x.mean(axis=0),\n",
    "                'cov': cov\n",
    "            }\n",
    "            self.priors[c] = float(len(y[y==c])) /len(y)\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        K = len(self.gaussians)\n",
    "        P = np.zeros((N,K))\n",
    "        for c,g in self.gaussians.items():\n",
    "            mean, cov = g['mean'], g['cov']\n",
    "            P[:,c]=mvn.logpdf(X, mean=mean, cov=cov) + np.log(self.priors[c])\n",
    "        return np.argmax(P, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classified:  0.7616503496503496\n",
      "Incorrect classified:  0.23834965034965036\n",
      "acuuracy: 0.7616503496503496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2914,    0,   29,   84,    8,  366,  108,    7,   10,    4],\n",
       "       [   0, 3761,  104,   21,    1,   52,   25,    7,   34,    6],\n",
       "       [  56,   59, 2681,  109,  146,   49,  224,   61,  153,   15],\n",
       "       [  35,   33,   97, 2638,   20,  343,   19,   41,  348,   76],\n",
       "       [   2,   71,   20,    3, 2520,   25,   84,   18,   38,  704],\n",
       "       [ 136,   91,   48,  377,  100, 2117,   57,   30,  118,  151],\n",
       "       [  45,   80,  184,   39,   48,  162, 2962,    0,    7,    2],\n",
       "       [  21,  188,   56,    2,  115,   59,    3, 3066,   69,  151],\n",
       "       [  39,  117,   97,  299,   35,  195,   27,   17, 2513,  151],\n",
       "       [  26,   61,   45,   39,  852,   81,    8,  250,  128, 2057]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = d1.iloc[:,0:9]\n",
    "y_train = d1.label\n",
    "\n",
    "model1 = BayesianClassifier(covariance_type='diag')\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model1.predict(X_train)\n",
    "correct = len(y_train[y_pred==y_train])/len(y_train)\n",
    "incorrect = len(y_train[y_pred!=y_train])/len(y_train)\n",
    "print('correct classified: ',correct)\n",
    "print('Incorrect classified: ',incorrect)\n",
    "print(\"acuuracy: {0}\".format(correct))\n",
    "metrics.confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classified:  0.8747132867132867\n",
      "Incorrect classified:  0.12528671328671329\n",
      "acuuracy: 0.8747132867132867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3336,    0,   13,   50,    4,   91,   21,    0,   12,    3],\n",
       "       [   0, 3856,   50,   29,    9,    7,    5,    4,   35,   16],\n",
       "       [  77,    3, 3126,   50,   99,   12,   79,   30,   61,   16],\n",
       "       [  27,   13,   75, 3089,    9,  115,    6,   37,  209,   70],\n",
       "       [  11,   11,   25,    3, 2907,    6,   49,   35,   19,  419],\n",
       "       [  99,    3,   13,   81,   48, 2786,   47,   21,   69,   58],\n",
       "       [  70,    6,   13,    1,   16,   52, 3342,    0,   25,    4],\n",
       "       [   8,   28,   78,    1,   40,   14,    2, 3319,   50,  190],\n",
       "       [  22,   57,   42,  206,   32,   94,   18,   14, 2899,  106],\n",
       "       [  31,   19,    8,   58,  529,   25,   17,  147,  102, 2611]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = d1.iloc[:,0:9]\n",
    "y_train = d1.label\n",
    "\n",
    "model2 = BayesianClassifier(covariance_type='full')\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model2.predict(X_train)\n",
    "correct = len(y_train[y_pred==y_train])/len(y_train)\n",
    "incorrect = len(y_train[y_pred!=y_train])/len(y_train)\n",
    "print('correct classified: ',correct)\n",
    "print('Incorrect classified: ',incorrect)\n",
    "print(\"acuuracy: {0}\".format(correct))\n",
    "metrics.confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build a Bayesian classifier on D2 (single Gaussian per class)\n",
    "Diagonal Covariance<br>\n",
    "Full covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classified:  0.8842797202797202\n",
      "Incorrect classified:  0.11572027972027972\n",
      "acuuracy: 0.8842797202797202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3330,    1,   24,   12,    5,   60,   45,    2,   46,    5],\n",
       "       [   1, 3723,   56,   13,    4,   13,    5,    5,  186,    5],\n",
       "       [  21,   22, 3090,  106,   40,   20,   90,   20,  133,   11],\n",
       "       [   3,   26,  129, 3098,    4,  154,   16,   50,  119,   51],\n",
       "       [   4,    8,   37,    4, 3135,   27,   23,    4,   50,  193],\n",
       "       [  27,    4,   50,  109,   17, 2702,   67,   27,  164,   58],\n",
       "       [  28,    3,   71,    3,   27,   78, 3273,    0,   46,    0],\n",
       "       [  19,   38,   34,   33,   63,    7,    2, 3274,   25,  235],\n",
       "       [  16,  104,   66,   89,   26,  170,   16,   11, 2933,   59],\n",
       "       [  22,    7,   19,   45,  171,   17,    1,  155,   55, 3055]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = d2.iloc[:,0:9]\n",
    "y_train = d2.label\n",
    "\n",
    "model3 = BayesianClassifier(covariance_type='diag')\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model3.predict(X_train)\n",
    "correct = len(y_train[y_pred==y_train])/len(y_train)\n",
    "incorrect = len(y_train[y_pred!=y_train])/len(y_train)\n",
    "print('correct classified: ',correct)\n",
    "print('Incorrect classified: ',incorrect)\n",
    "print(\"acuuracy: {0}\".format(correct))\n",
    "metrics.confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classified:  0.8969790209790209\n",
      "Incorrect classified:  0.10302097902097902\n",
      "acuuracy: 0.8969790209790209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3395,    0,   26,    7,    4,   33,   35,    4,   22,    4],\n",
       "       [   2, 3756,   58,   18,    3,    9,    1,   12,  148,    4],\n",
       "       [  31,   13, 3188,   83,   35,   21,   63,   23,   89,    7],\n",
       "       [  10,   13,  117, 3147,    4,  145,    9,   49,  114,   42],\n",
       "       [   4,    2,   44,    2, 3127,   23,   41,   23,   44,  175],\n",
       "       [  51,    5,   53,  109,   17, 2692,   58,   19,  176,   45],\n",
       "       [  33,    2,   55,    2,    7,   76, 3335,    0,   19,    0],\n",
       "       [   7,   11,   55,   37,   39,   13,    0, 3419,   41,  108],\n",
       "       [  24,  100,   62,   90,   40,  149,   39,    8, 2929,   49],\n",
       "       [  22,    2,   27,   52,  163,   25,    5,  136,   36, 3079]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = d2.iloc[:,0:9]\n",
    "y_train = d2.label\n",
    "\n",
    "model4 = BayesianClassifier(covariance_type='full')\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model4.predict(X_train)\n",
    "correct = len(y_train[y_pred==y_train])/len(y_train)\n",
    "incorrect = len(y_train[y_pred!=y_train])/len(y_train)\n",
    "print('correct classified: ',correct)\n",
    "print('Incorrect classified: ',incorrect)\n",
    "print(\"acuuracy: {0}\".format(correct))\n",
    "metrics.confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the test accuracies of the four classifiers and comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy of model 1 for testing dataset: 0.7585154639175258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1990,    0,   21,   57,    5,  249,   62,    1,    5,    3],\n",
       "       [   0, 2560,   65,   12,    2,   35,   19,   10,   25,    3],\n",
       "       [  47,   45, 1814,   68,  108,   32,  130,   41,  108,   12],\n",
       "       [  34,   24,   64, 1780,   12,  242,   13,   26,  234,   52],\n",
       "       [   3,   50,   33,    1, 1633,   13,   57,   10,   38,  519],\n",
       "       [  70,   62,   35,  240,   67, 1477,   35,   22,   82,  106],\n",
       "       [  31,   67,  114,   20,   34,  111, 2003,    0,    5,    4],\n",
       "       [  21,  124,   35,    1,   78,   34,    4, 2072,   43,  123],\n",
       "       [  38,   67,   52,  233,   31,  126,   12,   11, 1675,  116],\n",
       "       [  15,   40,   37,   23,  590,   49,    5,  156,   97, 1390]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [ 'pca'+str(i) for i in range(0,9) ]\n",
    "X_trans_test = pd.DataFrame(pca.transform(X_test), columns = col_names)\n",
    "\n",
    "y_test_pred = model1.predict(X_trans_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(\"acuuracy of model 1 for testing dataset: {0}\".format(accuracy))\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy of model 2 for testing dataset: 0.8715876288659794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2254,    0,    7,   28,    5,   65,   17,    1,   13,    3],\n",
       "       [   0, 2626,   31,   18,    8,    3,    1,    3,   30,   11],\n",
       "       [  61,    3, 2099,   32,   82,   13,   44,   18,   43,   10],\n",
       "       [  31,   11,   51, 2072,    8,   76,    7,   27,  141,   57],\n",
       "       [   7,    9,   20,    1, 1957,    6,   34,   18,   20,  285],\n",
       "       [  58,    1,    9,   64,   36, 1907,   32,   11,   46,   32],\n",
       "       [  52,    7,   12,    0,   17,   42, 2234,    0,   24,    1],\n",
       "       [  11,   10,   44,    3,   23,   12,    1, 2265,   41,  125],\n",
       "       [  21,   33,   31,  145,   23,   68,    8,   14, 1931,   87],\n",
       "       [  18,   15,    4,   47,  334,   20,   13,   91,   69, 1791]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model2.predict(X_trans_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(\"acuuracy of model 2 for testing dataset: {0}\".format(accuracy))\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy of model 3 for testing dataset: 0.870020618556701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2252,    0,   27,    4,    3,   38,   27,    2,   40,    0],\n",
       "       [   0, 2525,   42,    6,    3,    9,    3,    6,  133,    4],\n",
       "       [  22,   22, 2063,   72,   40,   10,   61,   22,   84,    9],\n",
       "       [   3,   20,  108, 2041,    4,  119,    7,   56,   91,   32],\n",
       "       [   3,   10,   32,    0, 2094,   20,   14,    4,   41,  139],\n",
       "       [  22,    5,   24,   85,   11, 1788,   56,   27,  129,   49],\n",
       "       [  34,    3,   56,    1,   21,   62, 2170,    0,   41,    1],\n",
       "       [  25,   31,   30,   25,   58,    9,    0, 2170,    8,  179],\n",
       "       [  16,   73,   32,   81,   19,  114,   16,    6, 1952,   52],\n",
       "       [  19,    6,    7,   37,  116,   14,    1,  120,   39, 2043]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [ 'lda'+str(i) for i in range(0,9) ]\n",
    "X_trans_test = pd.DataFrame(lda.transform(X_test), columns = col_names)\n",
    "\n",
    "y_test_pred = model3.predict(X_trans_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(\"acuuracy of model 3 for testing dataset: {0}\".format(accuracy))\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy of model 4 for testing dataset: 0.8845773195876289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2285,    0,   34,    1,    2,   26,   19,    1,   23,    2],\n",
       "       [   0, 2542,   49,    7,    5,    1,    2,    9,  112,    4],\n",
       "       [  23,   11, 2167,   53,   30,   13,   25,   20,   55,    8],\n",
       "       [  14,    7,  104, 2079,    4,  114,    1,   46,   85,   27],\n",
       "       [   4,    4,   34,    1, 2107,   14,   21,   10,   37,  125],\n",
       "       [  40,    4,   30,   79,   11, 1800,   47,   13,  131,   41],\n",
       "       [  20,    2,   56,    1,   10,   78, 2202,    0,   20,    0],\n",
       "       [  11,    7,   52,   23,   34,   13,    0, 2273,   32,   90],\n",
       "       [  14,   60,   39,   76,   24,  126,   21,    5, 1945,   51],\n",
       "       [  16,    1,   14,   39,  112,   28,    2,  100,   39, 2051]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model4.predict(X_trans_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(\"acuuracy of model 4 for testing dataset: {0}\".format(accuracy))\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model 1: PCA transformation + BayesianClassifier with covariance_type = 'diag' (d1 dataset)\n",
    "\n",
    "acuuracy of model 1 for training dataset: 0.7616503496503496<br>\n",
    "acuuracy of model 1 for testing dataset: 0.7585154639175258\n",
    "\n",
    "###### Model 2: PCA transformation + BayesianClassifier with covariance_type = 'full' (d1 dataset)\n",
    "\n",
    "acuuracy of model 2 for training dataset: 0.8747132867132867<br>\n",
    "acuuracy of model 2 for testing dataset: 0.8715876288659794\n",
    "\n",
    "###### Model 3: LDA transformation + BayesianClassifier with covariance_type = 'diag' (d2 dataset)\n",
    "\n",
    "acuuracy of model 3 for training dataset: 0.8842797202797202<br>\n",
    "acuuracy of model 3 for testing dataset: 0.870020618556701\n",
    "\n",
    "###### Model 4: LDA transformation + BayesianClassifier with covariance_type = 'full' (d2 dataset)\n",
    "\n",
    "acuuracy of model 4 for training dataset: 0.8969790209790209<br>\n",
    "acuuracy of model 4 for testing dataset: 0.8845773195876289\n",
    "\n",
    "We can see that model 4 accuracy for training and testing dataset is very high compare than other model. Hence, model4 is a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
